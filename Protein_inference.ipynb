{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "610830be-8d3f-4d72-938e-2c6ff5fa376d",
   "metadata": {},
   "source": [
    "# Protein infenrece\n",
    "We can find the most likely observed protein in a protein group by making an estimated guess using the annonation data from uniprot. By looking at reviewed status, annotation score, number of entry and enty name lenth (newer entries have longer names) we can find the most relevant protein. To compare search results, we then compare the gene names. \n",
    "\n",
    "Download the reference proteome from uniprot in tsv format (https://www.uniprot.org/proteomes/UP000005640) and select the data for gene names (primatry), annotation, go terms and whatever extra information you'd like to look at. Remeber, all isoforms are under the main entry for each protein. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c77315fa-a603-4962-bc9a-75ad5ca3c683",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf68261a-2348-49af-b8f9-f70dade80b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "annos = \"PATH_TO_ANNOTATIONS_FILE/uniprotkb_proteome_UP000005640_2025_03_18.tsv.gz\"\n",
    "\n",
    "f_path = \"PATH_TO_FASTA_FILE/HUMAN.fasta\"\n",
    "\n",
    "IN_PATH = \"PATH/proteinGroups.txt\"\n",
    "OUT_PATH = \"PATH/proteinGroups_w_uniprot.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f79472-b816-4807-ae9b-3e57abefd20c",
   "metadata": {},
   "source": [
    "# Protein inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7cad0323-6d4e-4c99-bd70-d220d22449fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_annos = pd.read_csv(annos, delimiter=\"\\t\")\n",
    "uni_annos['Gene Ontology IDs'] = uni_annos['Gene Ontology IDs'].fillna('')\n",
    "\n",
    "def count_go_and_keywords(row):\n",
    "    go_terms_count = len(row['Gene Ontology IDs'].split(\";\")) if row['Gene Ontology IDs'] else 0\n",
    "    keywords_count = len(row['Keywords'].split(\";\")) if row['Keywords'] else 0\n",
    "    return go_terms_count + keywords_count\n",
    "\n",
    "# Apply the function and add a new column with count of go terms\n",
    "uni_annos['Total Count'] = uni_annos.apply(count_go_and_keywords, axis=1)\n",
    "uni_annos['Entry name len'] = uni_annos['Entry'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50cf63d1-2a4b-4bc1-97b1-60b5e3883754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_uni(df, annos): \n",
    "    \n",
    "    for index, row in df.iterrows(): \n",
    "    \n",
    "        test_proteins = row['Proteins_list']\n",
    "        filtered_df = annos[annos['Entry'].isin(test_proteins)]\n",
    "\n",
    "        sorted_df = filtered_df.sort_values(by=['Reviewed', 'Total Count', 'Annotation', 'Entry', 'Entry name len'], ascending=[True, False, False, True, False])\n",
    "        sorted_df = sorted_df.reset_index(drop=True)\n",
    "\n",
    "        if not sorted_df.empty: \n",
    "\n",
    "            # Define output columns\n",
    "            df.at[index, 'Uniprot_cannonised'] = sorted_df['Entry'][0] # main extracted uniprot id\n",
    "            df.at[index, 'Gene_name'] = sorted_df['Gene Names (primary)'][0] # main extracted gene name\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67cccf18-9923-4575-bdf6-550375cc4dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_msms_MQ(datafile, uni_annos): \n",
    "    '''''''\n",
    "    data = pd.read_csv(datafile, delimiter=\"\\t\")\n",
    "    data['Proteins_list'] = data['Proteins'].apply(lambda x: x.split(';') if pd.notnull(x) else [])\n",
    "    data['Proteins_list'] = data['Proteins_list'].apply(lambda sublist: [item.split('-')[0] if '-' in item else item for item in sublist])\n",
    "    data['Uniprot_cannonised'] = \"\" \n",
    "    data['Gene_name'] = \"\"\n",
    "\n",
    "    data_cannonised = find_uni(data, uni_annos)\n",
    "    \n",
    "    return data_cannonised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e224911-8b81-4c3d-86cc-6ac745d2d3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pg_MQ(datafile, uni_annos):\n",
    "    data = pd.read_csv(datafile, delimiter=\"\\t\")\n",
    "    data['Proteins_list'] = data['Protein IDs'].apply(lambda x: x.split(';') if pd.notnull(x) else [])\n",
    "    data['Proteins_list'] = data['Proteins_list'].apply(lambda sublist: [item.split('|')[1] if '|' in item else item for item in sublist])\n",
    "    data['Uniprot_cannonised'] = \"\" \n",
    "    data['Gene_name'] = \"\"\n",
    "\n",
    "    data_cannonised = find_uni(data, uni_annos)\n",
    "    \n",
    "    return data_cannonised\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0122562b-21bc-4292-bd98-8e6ddae76f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processed = process_data_msms_MQ(IN_PATH, uni_annos)\n",
    "# save to tsv file\n",
    "data_processed.to_csv(OUT_PATH, index=False, sep = '\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
